<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name="google-site-verification" content="xDNWUvx6Q5EWK5YYSyKvK8DZTmvXhKsGX203Ll-BFFE" >	
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  <style type="text/css">
  @import url(http://fonts.googleapis.com/css?family=Roboto:400,400italic,500,500italic,700,700italic,900,900italic,300italic,300,100italic,100);
    /* Color scheme stolen from Sergey Karayev */
    a {
    /*color: #b60a1c;*/
    color: #1772d0;
    /*color: #bd0a36;*/
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Roboto', sans-serif;
    font-size: 15px;
    font-weight: 300;
    }
    strong {
    font-family: 'Roboto', sans-serif;
    /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
    /*font-family: 'Avenir Next';*/
    font-size: 15px;
    font-weight: 400;
    }
    heading {
    /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
    font-family: 'Roboto', sans-serif;
    /*font-family: 'Avenir Next';*/
    /*src: url("./fonts/Roboto_Mono_for_Powerline.ttf");*/
    font-size: 24px;
    font-weight: 400;
    }
    papertitle {
    /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
    font-family: 'Roboto', sans-serif;
    /*font-family: 'Avenir Next';*/
    /*src: url("./fonts/Roboto_Mono_for_Powerline.ttf");*/
    font-size: 15px;
    font-weight:500;
    }
    name {
    /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
    font-family: 'Roboto', sans-serif;
    /*font-family: 'Avenir Next';*/
    font-weight: 400;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 140px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="media/preview.jpg">
  <title>Songyou Peng - Homepage</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  <script src="script/functions.js"></script>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <!--<tr onmouseout="headshot_stop()" onmouseover="headshot_start()">-->
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>Songyou Peng (彭崧猷)</name>
          <!--<br>
          ruthfong at robots dot ox dot ac dot uk-->
        </p>
        <p>
          I am a PhD student at <a href="https://ethz.ch/en.html">ETH Zurich</a> and <a href="https://is.tuebingen.mpg.de/">Max Planck Institute for Intelligent Systems</a> under <a href="https://learning-systems.org/">Max Planck ETH Center for Learning Systems</a> & <a href="https://ellis.eu/">ELLIS</a>. I am co-supervised by <a href="https://inf.ethz.ch/personal/marc.pollefeys/"><strong>Marc Pollefeys</strong></a> and <a href="http://www.cvlibs.net/"><strong>Andreas Geiger</strong></a>. 
          <!-- I am currently a research intern at <a href="https://research.fb.com/category/augmented-reality-virtual-reality/">Facebook Reality Labs (FRL)</a>. -->
          I am currently a research intern at <a href="https://about.facebook.com/meta/">Meta</a> <a href="https://about.facebook.com/realitylabs/">Reality Labs Research</a>.
          <!-- I am currently working at <a href="http://www.cvlibs.net/">Autonomous Vision Group (AVG)</a> at MPI Tubingen. -->
          <!-- I am currently working at <a href="https://cvg.ethz.ch">Computer Vision & Geometry Group</a> at ETH Zurich. -->
        </p>  
        <p>
          I completed an Erasmus Mundus Masters in Computer Vision and Robotics (<a href="https://www.vibot.org/">VIBOT</a>) with distinction. During the master, I was fortunate to be supervised by <a href="https://vision.in.tum.de/members/cremers">Daniel Cremers</a> at <a href="https://vision.in.tum.de">Technical University of Munich</a> for my thesis and work with <a href="https://team.inria.fr/steep/en/people/peter-sturm/">Peter Sturm</a> at <a href="https://www.inria.fr/en/">INRIA</a> for two summers. Before this, I obtained a Bachelors in Automation at <a href="http://en.xjtu.edu.cn/">Xi'an Jiaotong University</a>.
        </p>

        <p>
          I have also spent some time at <a href="https://adsc.illinois.edu">ADSC</a> and <a href="https://www.a-star.edu.sg/">A*STAR</a> in Singapore.
          <!-- Previously, I was a research engineer at <a href="https://adsc.illinois.edu">Advanced Digital Sciences Center (ADSC)</a>, a research center of <a href="http://illinois.edu/">University of Illinois Urbana-Champaign (UIUC)</a> based in Singapore. I was also working at Institute for Infocomm Research (I2R), <a href="https://www.a-star.edu.sg/">Agency for Science, Technology and Research (A*STAR)</a>, Singapore.  -->
        </p>
<!--         <p> -->
<!--           I received a Bachelors in Computer Science at <a href="https://www.harvard.edu/">Harvard University</a> and worked with Professors <a href="http://coxlab.org/">David Cox</a> and <a href="https://www.wjscheirer.com/">Walter Scheirer</a> while there. I also spent lovely summer months at <a href="https://www.microsoft.com/">Microsoft</a>, <a href="https://www.apple.com/">Apple</a>, and <a href="https://www.deshaw.com/">D.E. Shaw</a>. -->
<!--         </p> -->
        <!--<p>I'm also supported by <a href="https://brianzhang01.github.io/">this fellow</a>.
        </p>-->
        <p align=center>
          <a href="mailto:songyou.peng@inf.ethz.ch">Email</a> &nbsp|&nbsp
          <a href="files/Songyou_2_page_CV.pdf">CV</a> &nbsp|&nbsp
          <!--<a href="files/ruth_fong_bio.txt">Biography</a> &nbsp/&nbsp-->
<!--           <a href="https://scholar.google.com/citations?user=39cUD3gAAAAJ">Google Scholar</a> &nbsp/&nbsp -->
          <a href="https://github.com/pengsongyou">GitHub</a> &nbsp|&nbsp
          <a href="https://scholar.google.com/citations?user=eNypkO0AAAAJ&hl=en">Google Scholar</a> &nbsp|&nbsp
          <a href="https://www.linkedin.com/in/songyou-peng-53717648/"> LinkedIn</a>
          &nbsp|&nbsp
          <a href="https://twitter.com/songyoupeng">Twitter</a>
        </p>
        </td>
        <td width="33%">
          <img src="media/profile.jpg" width="250" alt="headshot">
          <!--<div class="one">
          <div class="two" id="headshot_image"><img src="media/color_headshot.png" width="250" alt="headshot"></div>
          <img src="media/bw_headshot.png" width="250" alt="headshot">
          </div>
          <script type="text/javascript">
          function headshot_start() {
          document.getElementById('headshot_image').style.opacity = "1";
          }
          function headshot_stop() {
          document.getElementById('headshot_image').style.opacity = "0";
          }
          filters_stop()
          </script>-->
        </td>
        <!--<td width="33%">
        <img src="media/bw_headshot.png" width="250">
        <img src="media/color_headshot.png" width="250">
        </td>-->
      </tr>
      <!-- <td width="10%"><a href="adsc.illinois.edu"><img src="media/adsc_logo.png" width="100"></a></td>
      <td width="10%"><a href="https://www.inria.fr/en/"><img src="media/inria_logo.jpg" width="100"></a></td>
      <td width="10%"><a href="https://vision.in.tum.de"><img src="media/tum_logo.jpg" width="100"></a></td>
      <td width="10%"><a href="https://www.vibot.org"><img src="media/vibot_logo_transparent.png" width="50"></a></td> -->
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="10%" valign="middle">
          <a href="https://ethz.ch/en.html"><img src="media/eth_logo.png" width="120"></a>
        </td>
        <td width="10%" valign="middle">
          <a href="https://www.is.mpg.de/"><img src="media/mpi_logo.png" width="80"></a>
        </td>

        <td width="10%" valign="middle">
          <a href="https://about.facebook.com/realitylabs/"><img src="media/frl_logo.png" width="60"></a>
        </td>
        <td width="10%" valign="middle">
          <a href="https://www.inria.fr/en/"><img src="media/inria_logo.jpg" width="90"></a>
        </td>
        <td width="10%" valign="middle">
          <a href="https://vision.in.tum.de"><img src="media/tum_logo.jpg" width="60"></a>
        </td>	
        <td width="10%" valign="middle">
          <a href="https://www.vibot.org"><img src="media/vibot_logo_transparent.png" width="35"></a></td>
        </td>
        <td width="10%" valign="middle">
          <a href="https://en.xjtu.edu.cn/"><img src="media/xjtu_logo.png" width="50"></a></td>
        </td>	
        
        <!-- <td width="10%" valign="middle">
          <a href="https://ethz.ch/en.html"><img src="media/eth_logo.png" width="120"></a>
        </td>
        <td width="10%" valign="middle">
          <a href="https://www.is.mpg.de/"><img src="media/mpi_logo.png" width="80"></a>
        </td>
        <td width="10%" valign="middle">
          <a href="https://www.inria.fr/en/"><img src="media/inria_logo.jpg" width="100"></a>
        </td>
        <td width="10%" valign="middle">
          <a href="https://vision.in.tum.de"><img src="media/tum_logo.jpg" width="70"></a>
        </td>	
        <td width="10%" valign="middle">
          <a href="https://www.vibot.org"><img src="media/vibot_logo_transparent.png" width="40"></a></td>
        </td>
        <td width="10%" valign="middle">
          <a href="https://en.xjtu.edu.cn/"><img src="media/xjtu_logo.png" width="60"></a></td>
        </td>	 -->
      </tr>
      </table>




      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
          <heading>News</heading>
            <ul>
              <li><strong>03/2022</strong> Our paper <img src="media/nice-slam/like.png" width="30"><a href="https://pengsongyou.github.io/nice-slam"><strong>NICE-SLAM</strong></a> is accepted to <strong>CVPR 2022</strong>! </li>
              <li><strong>02/2022</strong> Invited to talk about <a href="https://pengsongyou.github.io/sap">Shape As Points</a> at <a href="https://twitter.com/talking_papers">Talking Papers Podcast</a>. Great chat with <a href="https://www.itzikbs.com/">Yizhak Ben-Shabat</a>!</li>
              <li><strong>12/2021</strong> Gave a talk again this year at <a href="http://games-cn.org/games-webinar-20211230-214/">GAMES Seminar Series</a> on <a href="https://pengsongyou.github.io/sap">Shape As Points</a>.</li>
              <li><strong>09/2021</strong> Our <a href="https://pengsongyou.github.io/sap">Shape As Points</a> is accepted to NeurIPS 2021 as <span style="color:#ff0000;"><strong>oral presentation</strong></span> <strong>(top 0.6%)</strong>!</li>
              <!-- <li><strong>09/2021</strong> <span style="color:#ff0000;"><strong>New!</strong></span> Our <a href="https://arxiv.org/abs/2106.03452">Shape As Points</a> is accepted to NeurIPS 2021 as <span style="color:#ff0000;"><strong>oral presentation</strong></span> <strong>(top 0.6%)</strong>!</li> -->
              <li><strong>08/2021</strong> Join <a href="https://research.fb.com/category/augmented-reality-virtual-reality/">Facebook Reality Labs (FRL)</a> as a research intern this fall.</li>
              <li><strong>07/2021</strong> Two papers (<a href="https://moechsle.github.io/unisurf/">UNISURF</a> and <a href="https://creiser.github.io/kilonerf/">KiloNeRF</a>) are accepted to ICCV 2021! </li>
              <li><strong>06/2021</strong> Gave a talk at <a href="http://games-cn.org/games-webinar-20210621-187/">GAMES Seminar Series</a> on <a href="files/Towards_Practical_Application_of_NeRF.pdf">Towards Practical Applications of NeRF</a>. </li>

              <a href="javascript:toggleblock(&#39;old_news&#39;)">---- show more ----</a>
              <div id="old_news" style="display: none;">

              <li><strong>11/2020</strong>: A <a href="https://github.com/dsvilarkovic/dynamic_plane_convolutional_onet">master course project</a> that I advised on got accepted to WACV 2021.</li>
              <li><strong>08/2020</strong>: Start my 1-year stay at <a href="http://www.cvlibs.net/">Autonomous Vision Group (AVG)</a> at MPI Tübingen.</li>
              <li><strong>07/2020</strong> Our paper <a href="https://arxiv.org/abs/2003.04618">Convolutional Occupancy Networks</a> is accepted to ECCV 2020 as <strong>spotlight (top 5%)</strong>! </li>
              <li><strong>09/2019</strong> Start PhD journey at <a href="https://learning-systems.org/">Max Planck ETH Center for Learning Systems</a>!</li>
              
              <!-- <a href="javascript:toggleblock(&#39;old_news&#39;)">---- show more ----</a>
              <div id="old_news" style="display: none;"> -->

              <li><strong>07/2019</strong> Our paper <a href="https://arxiv.org/abs/1811.03264">Calibration Wizard</a> is accepted to ICCV 2019 as <strong>oral presentation (top 4.6%) </strong>.</li>
              <li><strong>06/2019</strong>: The extension of my master thesis got accepted to TPAMI 2019! 
            </div></div>
            </ul>
        </td>
      </tr>
      <tr>
        <td width="100%" valign="middle">
          <heading>Research</heading>
        </td>
      </tr>
      </table>
    
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" >
    
        <tr onmouseout="nice_stop()" onmouseover="nice_start()">  
          <td width="25%">
            <div class="one">
            <div class="two" id = 'nice_shape'>
            <video  width="160" height="90" muted autoplay loop>
                <source src="media/nice_teaser.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video></div>
            <img src='media/nice_teaser.jpg' width="160" height="90"></div>
            <script type="text/javascript">
            function nice_start() { 
            document.getElementById('nice_shape').style.opacity = "1";
            }
            function nice_stop() { 
            document.getElementById('nice_shape').style.opacity = "0"; 
            }
      nice_stop()
            </script>
            </script>
          </td>
          <td valign="top" width="75%">
              <a href="https://pengsongyou.github.io/nice-slam">
                <papertitle>
                  NICE-SLAM: Neural Implicit Scalable Encoding for SLAM
                </papertitle>
              </a>
          <br>
              <a href="https://zzh2000.github.io">Zihan Zhu</a>*,
              <strong>Songyou Peng*</strong>,
              <a href="http://people.inf.ethz.ch/vlarsson/">Viktor Larsson</a>,
              <a href="http://www.cad.zju.edu.cn/home/weiweixu/weiweixu_en.htm"> Weiwei Xu</a>,
              <a href="http://www.cad.zju.edu.cn/home/bao/"> Hujun Bao</a>,
              <a href="https://zhpcui.github.io/"> Zhaopeng Cui</a>,
              <a href="http://people.inf.ethz.ch/moswald/"> Martin R. Oswald</a>,
              <a href="https://inf.ethz.ch/personal/marc.pollefeys/">Marc Pollefeys</a>
          <br>
              <em>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2022
          <br>
            (* equal contribution)
            <br>
            <a href="https://arxiv.org/abs/2112.12130">paper</a> |
            <a href="https://pengsongyou.github.io/nice-slam">project page</a>
            <!-- <a href="https://youtu.be/FL8LMk_qWb4">video (6 min)</a> | -->
            <!-- <a href="https://github.com/autonomousvision/shape_as_points">code</a> -->
            <p></p>
            A neural implicit-based RGB-D SLAM that can be applied to large-scale scenes.
            <p></p>
          </td>
        </tr>
    
    
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" >
      <tr onmouseout="sap_stop()" onmouseover="sap_start()">  
      <td width="25%">
        <div class="one">
        <div class="two" id = 'sap_shape'>
        <video  width="160" height="120" muted autoplay loop>
            <source src="media/sap_teaser.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video></div>
        <img src='media/sap_teaser.jpg' width="160" height="120"></div>
        <script type="text/javascript">
        function sap_start() { 
        document.getElementById('sap_shape').style.opacity = "1";
        }
        function sap_stop() { 
        document.getElementById('sap_shape').style.opacity = "0"; 
        }
  sap_stop()
        </script>
        </script>
      </td>
      <td valign="top" width="75%">
          <a href="https://pengsongyou.github.io/sap">
            <papertitle>
              Shape As Points: A Differentiable Poisson Solver
            </papertitle>
          </a>
      <br>
          <strong>Songyou Peng</strong>,
          <a href="https://www.maxjiang.ml/">Chiyu "Max" Jiang</a>,
          <a href="https://yiyiliao.github.io/">Yiyi Liao</a>,
          <a href="https://m-niemeyer.github.io/">Michael Niemeyer</a>,
          <a href="https://inf.ethz.ch/personal/marc.pollefeys/">Marc Pollefeys</a>,
          <a href="http://www.cvlibs.net/">Andreas Geiger</a>
      <br>
          <em><strong>NeurIPS</strong></em>, 2021 <strong>(<span style="color:#ff0000;">Oral</span>, top 0.6%)</strong>
      <br>
        <a href="https://arxiv.org/abs/2106.03452">paper</a> |
        <a href="https://pengsongyou.github.io/sap">project page</a> |
        <a href="https://youtu.be/FL8LMk_qWb4">video (6 min)</a> |
        <a href="https://youtu.be/TgR0NvYty0A">video (12 min)</a> |
        <a href="https://talking.papers.podcast.itzikbs.com/1914034/10135005-songyou-peng-shape-as-points">podcast</a> | 
        <a href="https://github.com/autonomousvision/shape_as_points">code</a>        
        <p></p>
        An interpretable hybird shape representation that yields HQ watertight meshes at low inference times.
        <p></p>
      </td>
    </tr>


<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" >
    <tr onmouseout="unisurf_stop()" onmouseover="unisurf_start()">  
      <td width="25%">
        <div class="one">
        <div class="two" id = 'unisurf_shape'>
        <img src='media/unisurf_shape2.jpg' width="160" height="130"></div>
        <img src='media/unisurf_rgb2.jpg' width="160" height="130"></div>
        </div>
        <script type="text/javascript">
        function unisurf_start() { 
        document.getElementById('unisurf_shape').style.opacity = "1";
        }
        function unisurf_stop() { 
        document.getElementById('unisurf_shape').style.opacity = "0"; 
        }
        unisurf_stop()
        </script>
        </script>
      </td>
      <td valign="top" width="75%">
            <a href="https://moechsle.github.io/unisurf/">
            <papertitle>UNISURF: Unifying Neural Implicit Surfaces and Radiance Fields for Multi-View Reconstruction</papertitle></a>
      <br>
      	  <a href="https://avg.is.tuebingen.mpg.de/person/moechsle">Michael Oechsle</a>,
      	  <strong>Songyou Peng</strong>,
          <a href="http://www.cvlibs.net/">Andreas Geiger</a>
      <br>
          <em>International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2021  <strong>(<span style="color:#ff0000;">Oral</span>, top 3%)</strong>
   
      <br>
        <a href="https://arxiv.org/abs/2104.10078">paper</a> |
	<a href="https://moechsle.github.io/unisurf/">project page</a> |
        <a href="https://youtu.be/WXUfHvZge0E">video</a> |
        <a href="https://youtu.be/OSHlNS6ytkc">teaser video</a> |
        <a href="https://github.com/autonomousvision/unisurf">code</a>
        <p></p>
          Our method enables to reconstruct accurate surfaces without input masks.
        <p></p>
      </td>
    </tr>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" >
    <tr onmouseout="kilo_stop()" onmouseover="kilo_start()">  
      <td width="25%">
        <div class="one">
        <div class="two" id = 'kilo_shape'>
        <video  width="160" height="130" muted autoplay loop>
            <source src="media/kilo_teaser.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video></div>
        <img src='media/kilo_teaser.jpg' width="150" height="120"></div>
        <script type="text/javascript">
        function kilo_start() { 
        document.getElementById('kilo_shape').style.opacity = "1";
        }
        function kilo_stop() { 
        document.getElementById('kilo_shape').style.opacity = "0"; 
        }
	kilo_stop()
        </script>
        </script>
      </td>
      <td valign="top" width="75%">
            <a href="https://creiser.github.io/kilonerf/">
            <papertitle>KiloNeRF: Speeding up Neural Radiance Fields with Thousands of Tiny MLPs</papertitle></a>
      <br>
      	  <a href="https://avg.is.tuebingen.mpg.de/person/creiser">Christian Reiser</a>,
      	  <strong>Songyou Peng</strong>,
      	  <a href="https://yiyiliao.github.io/">Yiyi Liao</a>,
      	  <a href="http://www.cvlibs.net/">Andreas Geiger</a>
      <br>
          <em>International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2021
      <br>
        <a href="https://arxiv.org/abs/2103.13744">paper</a> |
        <a href="https://creiser.github.io/kilonerf/">project page</a> |
        <a href="https://autonomousvision.github.io/kilonerf/">blog</a> |
        <a href="https://youtu.be/PNh0LvMpovU">video</a> |
        <a href="https://youtu.be/qvsMMDonF28">teaser video</a> |
        <a href="https://github.com/creiser/kilonerf">code</a>
        
        <p></p>
        Over 2000x speed-ups for NeRF are possible by utilizing thousands of tiny MLPs.
        <p></p>
      </td>
    </tr>


<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" >
    <tr onmouseout="dpcon_stop()" onmouseover="dpcon_start()">  
      <td width="25%">
        <div class="one">
        <div class="two" id = 'dpcon_shape'>
        <img src='media/dp-con.png' width="160" height="120"></div>
        <img src='media/dp-con.png' width="160" height="120"></div>
        </div>
        <script type="text/javascript">
        function dpcon_start() { 
        document.getElementById('dpcon_shape').style.opacity = "1";
        }
        function dpcon_stop() { 
        document.getElementById('dpcon_shape').style.opacity = "0"; 
        }
        dpcon_stop()
        </script>
        </script>
      </td>
      <td valign="top" width="75%">
      		<a href="https://github.com/dsvilarkovic/dynamic_plane_convolutional_onet">
            <papertitle>Dynamic Plane Convolutional Occupancy Networks</papertitle></a>
      <br>
      	  <a href="https://www.google.com/search?q=Stefan+Lionar">Stefan Lionar*</a>,
      	  <a href="https://www.google.com/search?q=Daniil+Emtsev">Daniil Emtsev*</a>,
          <a href="https://www.google.com/search?q=Dusan+Svilarkovic">Dusan Svilarkovic*</a>,
          <strong>Songyou Peng</strong>
      <br>
          <em>Winter Conference on Applications of Computer Vision (<strong>WACV</strong>)</em>, 2021
          <br>
   		  (* equal contribution)
      <br>
        <a href="https://arxiv.org/abs/2011.05813">paper</a> |
        <a href="https://screencast-o-matic.com/watch/cYXOcaLKJz">video</a> |
        <a href="https://github.com/dsvilarkovic/dynamic_plane_convolutional_onet">code</a>
        <!-- <a href="https://github.com/B1ueber2y/DIST-Renderer">code</a> -->
        <p></p>
        A student project of 3D Vision course at ETH Zurich where I served as the advisor.
        <p></p>
      </td>
    </tr>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" >
    <tr onmouseout="con_stop()" onmouseover="con_start()">  
      <td width="25%">
        <div class="one">
        <div class="two" id = 'con_shape'>
        <img src='media/con_teaser.gif' width="160" height="120"></div>
        <img src='media/con_teaser_in.png' width="160" height="120"></div>
        </div>
        <script type="text/javascript">
        function con_start() { 
        document.getElementById('con_shape').style.opacity = "1";
        }
        function con_stop() { 
        document.getElementById('con_shape').style.opacity = "0"; 
        }
        con_stop()
        </script>
        </script>
      </td>
      <td valign="top" width="75%">
      		<a href="https://pengsongyou.github.io/conv_onet">
            <papertitle>Convolutional Occupancy Networks</papertitle></a>
      <br>
      	  <strong>Songyou Peng</strong>, 
      	  <a href="https://m-niemeyer.github.io/">Michael Niemeyer</a>,
      	  <a href="https://is.tuebingen.mpg.de/person/lmescheder">Lars Mescheder</a>,
          <a href="https://inf.ethz.ch/personal/marc.pollefeys/">Marc Pollefeys</a>,
          <a href="http://www.cvlibs.net/">Andreas Geiger</a>
      <br>
          <em>European Conference on Computer Vision (<strong>ECCV</strong>)</em>, 2020 <strong>(<span style="color:#ff0000;">Spotlight</span>, top 5%)</strong>
   
      <br>
        <a href="http://www.cvlibs.net/publications/Peng2020ECCV.pdf">paper</a> |
        <!-- <a href="http://www.cvlibs.net/publications/Peng2020ECCV_supplementary.pdf">supplementary</a> | -->
        <a href="https://pengsongyou.github.io/conv_onet">project page</a> |
        <a href="https://autonomousvision.github.io/convolutional-occupancy-networks/">blog</a> |
        <a href="https://www.youtube.com/watch?v=EmauovgrDSM">video</a> |
        <a href="https://youtu.be/k0monzIcjUo">teaser video</a> |
        <a href="https://github.com/autonomousvision/convolutional_occupancy_networks">code</a>
        <p></p>
         A flexible implicit representation for accurate large-scale 3D reconstruction.
        <p></p>
      </td>
    </tr>


<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

    <!-- <tr onmouseout="wizard_stop()" onmouseover="wizard_start()" bgcolor="#ffffd0"> -->
    <tr onmouseout="dist_stop()" onmouseover="dist_start()">  
      <td width="25%">
        <div class="one">
        <div class="two" id = 'dist_shape'>
        <img src='media/dist.gif' width="160" height="100"></div>
        <img src='media/dist.jpg' width="160" height="100"></div>
        </div>
        <script type="text/javascript">
        function dist_start() { 
        document.getElementById('dist_shape').style.opacity = "1";
        }
        function dist_stop() { 
        document.getElementById('dist_shape').style.opacity = "0"; 
        }
        dist_stop()
        </script>
        </script>
      </td>
      <td valign="top" width="75%">
      		<a href="http://b1ueber2y.me/projects/DIST-Renderer/">
            <papertitle>DIST: Rendering Deep Implicit Signed Distance Function with Differentiable Sphere Tracing</papertitle></a>
      <br>
          <a href="http://b1ueber2y.me">Shaohui Liu</a>, 
          <a href="https://www.zhangyinda.com">Yinda Zhang</a>, 
          <strong>Songyou Peng</strong>, 
          <a href="https://ci.idm.pku.edu.cn">Boxin Shi</a>, 
          <a href="https://inf.ethz.ch/personal/marc.pollefeys/">Marc Pollefeys</a>,
          <a href="https://zhpcui.github.io/">Zhaopeng Cui</a>
      <br>
          <em>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2020
   
      <br>
        <a href="https://arxiv.org/abs/1911.13225">paper</a> |
        <a href="http://b1ueber2y.me/projects/DIST-Renderer/">project page</a> |
        <a href="media/dist-1min.mp4">teaser video</a> |
        <a href="http://b1ueber2y.me/projects/DIST-Renderer/pdf/4986-poster.pdf">poster</a> |
        <a href="https://github.com/B1ueber2y/DIST-Renderer">code</a>
        <p></p>
        A differentiable renderer for deep implicit signed distance functions.
        <p></p>
      </td>
    </tr>


<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

    <!-- <tr onmouseout="wizard_stop()" onmouseover="wizard_start()" bgcolor="#ffffd0"> -->
    <tr onmouseout="wizard_stop()" onmouseover="wizard_start()">	
      <td width="25%">
        <div class="one">
        <div class="two" id = 'wizard_shape'>
        <img src='media/wizard2.jpg' width="160" height="110"></div>
        <img src='media/wizard1.jpg' width="160" height="110"></div>
        </div>
        <script type="text/javascript">
        function wizard_start() { 
        document.getElementById('wizard_shape').style.opacity = "1";
        }
        function wizard_stop() { 
        document.getElementById('wizard_shape').style.opacity = "0"; 
        }
        wizard_stop()
        </script>
        </script>
      </td>
      <td valign="top" width="75%">
      		<a href="https://github.com/pengsongyou/CalibrationWizard">
            <papertitle>Calibration Wizard: A Guidance System for Camera Calibration Based on Modelling Geometric and Corner Uncertainty</papertitle></a>
      <br>
          <strong>Songyou Peng</strong> and  
          <a href="https://team.inria.fr/steep/people/peter-sturm/">Peter Sturm</a>
      <br>
          <em>International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2019  <strong>(<span style="color:#ff0000;">Oral</span>, top 4.6%)</strong>
   
      <br>
        <a href="https://arxiv.org/pdf/1811.03264.pdf">paper</a> |
        <a href="https://youtu.be/my3jocjpD0U?t=398">video</a> |
		<a href="files/iccv19_poster.pdf">poster</a> |
        <a href="https://github.com/pengsongyou/CalibrationWizard">code</a>
        <p></p>
        A novel system that interactively guides a user to take optimal calibration images.
        <p></p>
      </td>
    </tr>


  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

    <tr onmouseout="pami_stop()" onmouseover="pami_start()">
      <td width="25%">
        <div class="one">
        <div class="two" id = 'pami_shape'>
        <img src='media/face_out.jpg' width="160" height="120"></div>
        <img src='media/face_in.jpg' width="160" height="120"></div>
        </div>
        <script type="text/javascript">
        function pami_start() { 
        document.getElementById('pami_shape').style.opacity = "1";
        }
        function pami_stop() { 
        document.getElementById('pami_shape').style.opacity = "0"; 
        }
        pami_stop()
        </script>
        </script>
      </td>
      <td valign="top" width="75%">
      		<a href="https://vision.in.tum.de/data/datasets/photometricdepthsr">
            <papertitle>Photometric Depth Super-Resolution</papertitle></a>
      <br>
          <a href="https://vision.in.tum.de/members/haefner">Bjoern Haefner</a>*, <strong>Songyou Peng*</strong>, 
          <a href="">Alok Verma</a>*, 
          <a href="https://sites.google.com/view/yvainqueau">Yvain Queau</a>, 
          <a href="https://vision.in.tum.de/members/cremers">Daniel Cremers</a> 
      <br>
          <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2019</em>
      <br>
           (* equal contribution)
      <br>
        <a href="https://arxiv.org/abs/1809.10097">paper</a> |
        <a href="https://vision.in.tum.de/data/datasets/photometricdepthsr">project page</a> 
        <p></p>
        Recover high-resolution depth maps with fine geometric details using photometric techniques.
        <p></p>
      </td>
    </tr>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

    <tr onmouseout="persemon_stop()" onmouseover="persemon_start()">
      <td width="25%">
        <div class="one">
        <div class="two" id = 'persemon_shape'>
        <img src='media/persemon2.jpg' width="160" height="90"></div>
        <img src='media/persemon2.jpg' width="160" height="90"></div>
        </div>
        <script type="text/javascript">
        function persemon_start() { 
        document.getElementById('persemon_shape').style.opacity = "1";
        }
        function persemon_stop() { 
        document.getElementById('persemon_shape').style.opacity = "0"; 
        }
        persemon_stop()
        </script>
        </script>
      </td>
      <td valign="top" width="75%">
      		<a href="https://github.com/ZhangLeUestc/PersEmoN">
            <papertitle>PersEmoN: A Deep Network for Joint Analysis of Apparent Personality, Emotion and Their Relationship</papertitle>
      <br>
          <a href="https://zhangleuestc.github.io">Le Zhang</a>, <strong>Songyou Peng</strong>, <a href="https://stefan.winkler.site">Stefan Winkler</a>
      <br>
          <em>IEEE Transactions on Affective Computing (<strong>TAFFC</strong>), 2019. In press. </em>
      <br>
        <a href="https://arxiv.org/pdf/1811.08657.pdf">paper</a> |
		<a href="https://github.com/ZhangLeUestc/PersEmoN">code</a>
        <p></p>
        A journal extension of our ACM MM 2018 paper.
        <p></p>
      </td>
    </tr>
  


    
    <tr onmouseout="personality_stop()" onmouseover="personality_start()">
      <td width="25%">
        <div class="one">
        <div class="two" id = 'personality_image'><img src='media/acmmm_demo.gif' width="160" height="110"></div>
        <img src='media/acmmm_demo_still.jpg' width="160" height="110">
        </div>
        <script type="text/javascript">
        function personality_start() {
        document.getElementById('personality_image').style.opacity = "1";
        }
        function personality_stop() {
        document.getElementById('personality_image').style.opacity = "0";
        }
        personality_stop()
        </script>
        </script>
      </td>
      <td valign="top" width="75%">
      		<a href="https://github.com/ZhangLeUestc/PersEmoN">
            <papertitle>Give Me One Portrait Image, I Will Tell You Your Emotion and Personality</papertitle></a>
      <br>
          <strong>Songyou Peng</strong>, <a href="https://zhangleuestc.github.io">Le Zhang</a>, <a href="https://stefan.winkler.site">Stefan Winkler</a>, <a href="http://winslett.cs.illinois.edu/">Marianne Winslett</a>
      <br>
        <em>ACM International Conference on Multimedia (<strong>ACM MM</strong>)</em>, 2018
        <br>
        <a href="files/mm18_personality_paper.pdf">paper</a> |
        <a href="files/mm18_personality_slide.pdf">slides</a> |
        <a href="https://github.com/ZhangLeUestc/PersEmoN">code</a>
        <p></p>
        <p>Technical Demo. A deep Siamese-like network is introduced to predict one's Big-Five personality and arousal-valence emotion from one portrait photo.</p>
      </td>
    </tr>

    <tr onmouseout="iccvw_stop()" onmouseover="iccvw_start()">
      <td width="25%">
        <div class="one">
        <div class="two" id = 'iccvw_shape'><img src='media/iccvw17_pic2.jpg' width="160" height="110"></div>
        <img src='media/iccvw17_pic1.jpg' width="160" height="110"></div>
        <!--<img src='media/selectivity_1.png' width="160" height="130">-->
        </div>
        <script type="text/javascript">
        function iccvw_start() {
        document.getElementById('iccvw_shape').style.opacity = "1";
        }
        function iccvw_stop() {
        document.getElementById('iccvw_shape').style.opacity = "0";
        }
        iccvw_stop()
        </script>
        </script>
      </td>
      <td valign="top" width="75%">
      		<a href="https://vision.in.tum.de/data/datasets/photometricdepthsr">
            <papertitle>Depth Super-Resolution Meets Uncalibrated Photometric Stereo</papertitle></a>
      <br>
          <strong>Songyou Peng</strong>, <a href="https://vision.in.tum.de/members/haefner">Bjoern Haefner</a>, <a href="https://vision.in.tum.de/members/queau">Yvain Queau</a>, <a href="https://vision.in.tum.de/members/cremers">Daniel Cremers</a>
      <br>
        <em>International Conference on Computer Vision (<strong>ICCV</strong>) Workshops</em>, 2017
        <br>
        <a href="http://openaccess.thecvf.com/content_ICCV_2017_workshops/w43/html/Peng_Depth_Super-Resolution_Meets_ICCV_2017_paper.html">paper</a> |
        <a href="files/iccvw17_presentation.pdf">slides</a> |
        <a href="https://github.com/pengsongyou/SRmeetsPS">code & data</a>
        <p></p>
        <p>A novel depth super-resolution approach for RGB-D sensors is presented.</p>
        <p>This paper a part of my master thesis, and subsumed by our <a href="https://arxiv.org/abs/1809.10097">TPAMI paper</a>.</p>
      </td>
    </tr>

    <tr onmouseout="msc_stop()" onmouseover="msc_start()">
      <td width="25%">
        <div class="one">
        <div class="two" id = 'msc_shape'><img src='media/ratio_shoe_shape.jpg' width="160" height="120"></div>
        <img src='media/ratio_shoe_rgb.jpg' width="160" height="120">
        <!--<img src='media/selectivity_1.png' width="160" height="130">-->
        </div>
        <script type="text/javascript">
        function msc_start() {
        document.getElementById('msc_shape').style.opacity = "1";
        }
        function msc_stop() {
        document.getElementById('msc_shape').style.opacity = "0";
        }
        msc_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <p>
        <a href="https://github.com/pengsongyou/msc-thesis">
        <papertitle>High Quality Shape from a RGB-D Camera using Photometric Stereo</papertitle></a>
        <br>
          <strong>Songyou Peng</strong> 
        <br>
        <em>M.Sc. Thesis</em>, Techinical University of Munich<br>
        Supervisor: <a href="https://vision.in.tum.de/members/queau">Yvain Queau</a> and <a href="https://vision.in.tum.de/members/cremers">Daniel Cremers</a> 
        <br>
        <a href="https://github.com/pengsongyou/msc-thesis">thesis</a> |
        <a href="bib/peng2017msc.txt">bibtex</a> |
        <a href="files/msc_poster.pdf">poster</a>
        <p></p>
        <p></p>
      </td>
    </tr>
  
  </table>
    

  <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <heading>Invited Talks</heading>
        </td>
      </tr>
  </table> -->

  <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"> -->
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:collapse;margin-right:auto;margin-left:auto;">
    <heading>Invited Talks</heading>
    <!-- <p></p> -->
    <br><br><br>
      
    <tr>
      <tr onmouseout="basel_stop()" onmouseover="basel_start()">  
      <td width="25%">
        <div class="one">
        <div class="two" id = 'gsap_shape'>
        <img src='media/talk_basel.jpg' width="180" height="100"></div>
        <img src='media/talk_basel.jpg' width="180" height="100"></div>
        </div>
        <script type="text/javascript">
        function basel_start() { 
        document.getElementById('gsap_shape').style.opacity = "1";
        }
        function basel_stop() { 
        document.getElementById('gsap_shape').style.opacity = "0"; 
        }
        basel_stop()
        </script>
      </td>
      <td valign="top" width="75%">
      <!-- <td style="padding:20px;width:75%;vertical-align:top">   -->
          <a href="files/neural_scene_rep_for_3d_rec.pdf">
            <papertitle>Neural Scene Representations for 3D Reconstruction</papertitle></a>
      <br>
          <strong>Songyou Peng</strong>
      <br>
          <em>University of Basel</em>, 2022
      <br>
        <a href="files/neural_scene_rep_for_3d_rec.pdf">slides</a>
        <!-- <a href="https://www.bilibili.com/video/BV1vb4y1n7b8">talk (in Chinese)</a> -->
      </td>
    </tr>

    <tr>
      <tr onmouseout="talking_stop()" onmouseover="talking_start()">  
      <td width="25%">
        <div class="one">
        <div class="two" id = 'gsap_shape'>
        <img src='media/talking_papers.jpg' width="180" height="100"></div>
        <img src='media/talking_papers.jpg' width="180" height="100"></div>
        </div>
        <script type="text/javascript">
        function talking_start() { 
        document.getElementById('gsap_shape').style.opacity = "1";
        }
        function talking_stop() { 
        document.getElementById('gsap_shape').style.opacity = "0"; 
        }
        talking_stop()
        </script>
      </td>
      <td valign="top" width="75%">
      <!-- <td style="padding:20px;width:75%;vertical-align:top">   -->
          <a href="https://www.itzikbs.com/shape-as-points-a-differentiable-poisson-solver">
            <papertitle>Shape As Points: A Differentiable Poisson Solver</papertitle></a>
      <br>
          <strong>Songyou Peng</strong>
      <br>
          <em><a href="https://talking.papers.podcast.itzikbs.com/">Talking Papers Podcast</a></em>, 2022
      <br>
        <a href="https://youtu.be/1bZaKno2FFg">video</a> |
        <a href="https://talking.papers.podcast.itzikbs.com/1914034/10135005-songyou-peng-shape-as-points">podcast</a>
      </td>
    </tr>


    <tr onmouseout="gsap_stop()" onmouseover="gsap_start()">  
      <td width="25%">
        <div class="one">
        <div class="two" id = 'gsap_shape'>
        <img src='media/games_sap.jpg' width="180" height="100"></div>
        <img src='media/games_sap.jpg' width="180" height="100"></div>
        </div>
        <script type="text/javascript">
        function gsap_start() { 
        document.getElementById('gsap_shape').style.opacity = "1";
        }
        function gsap_stop() { 
        document.getElementById('gsap_shape').style.opacity = "0"; 
        }
        gsap_stop()
        </script>
      </td>
      <td valign="top" width="75%">
          <a href="media/sap/SAP_NeurIPS_GAMES.pdf">
            <papertitle>Shape As Points: A Differentiable Poisson Solver</papertitle></a>
      <br>
          <strong>Songyou Peng</strong>
      <br>
          <em> Graphics And Mixed Environment Seminar (<strong>GAMES</strong>)</em>, 2021
      <br>
        <a href="media/sap/SAP_NeurIPS_GAMES.pdf">slides</a> |
        <a href="https://www.bilibili.com/video/BV1vb4y1n7b8">talk (in Chinese)</a>
      </td>
    </tr>
  <!-- </table> -->
  <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" > -->
    <tr onmouseout="gnerf_stop()" onmouseover="gnerf_start()">  
      <td width="25%">
        <div class="one">
        <div class="two" id = 'gnerf_shape'>
        <img src='media/games_nerf.png' width="160" height="100"></div>
        <img src='media/games_nerf.png' width="160" height="100"></div>
        </div>
        <script type="text/javascript">
        function gnerf_start() { 
        document.getElementById('gnerf_shape').style.opacity = "1";
        }
        function gnerf_stop() { 
        document.getElementById('gnerf_shape').style.opacity = "0"; 
        }
        gnerf_stop()
        </script>
      </td>
      <td valign="top" width="75%">
          <a href="files/Towards_Practical_Application_of_NeRF.pdf">
            <papertitle>Towards Practical Applications of NeRF</papertitle></a>
      <br>
          <strong>Songyou Peng</strong>
      <br>
          <em> Graphics And Mixed Environment Seminar (<strong>GAMES</strong>)</em>, 2021
      <br>
        <a href="files/Towards_Practical_Application_of_NeRF.pdf">slides</a> |
        <a href="https://www.bilibili.com/video/BV1f54y1H7cY">talk (in Chinese)</a>   
      </td>
    </tr>
  </table>

      <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <heading>Selected Projects</heading>
        </td>
      </tr>
      </table> -->
      <table width="100%" align="center" border="0" cellpadding="20">
        <heading>Selected Projects</heading>
    <tr onmouseout="dna_stop()" onmouseover="dna_start()">
      <td width="25%">
        <div class="one">
        <div align="center" class="two" id='dna_gif'><img src='media/OMG_logo.png' width="150" height="80"></div>
        <div align="center" class="two" id='dna_image'><img src='media/OMG_logo.png' width="150" height="80"></div>
        </div>
        <script type="text/javascript">
        function dna_start() {
        document.getElementById('dna_gif').style.opacity = "1";
        }
        function dna_stop() {
        document.getElementById('dna_gif').style.opacity = "0";
        }
        dna_stop()
        </script>
      </td>
        <!--<td width="25%"><img src="media/gwas.png" alt="GWAS image from https://upload.wikimedia.org/wikipedia/commons/5/59/GWAS_loci_influencing_human_facial_and_scalp_hair_phenotypes_-_cropped.png" width="160" height="160"></td>-->
      <!--<tr>
        <td width="25%"><img src="media/benedict_1.png" alt="benedict-otter-look-a-like" width="160" height="160"></td>-->
        <td width="75%" valign="top">
        <p>
          <a href="https://github.com/PaolaArdon/Salt-Pepper">
          <papertitle>A Deep Network for Arousal-Valence Emotion Prediction with Acoustic-Visual Cues</papertitle>
          </a>
          <br>
          <strong>Songyou Peng</strong>, <a href="https://zhangleuestc.github.io">Le Zhang</a>, <a href="https://team.inria.fr/perception/team-members/yutong-ban/">Yutong Ban</a>, <a href="http://people.eng.unimelb.edu.au/mengf1/">Meng Fang</a>, <a href="stefan.winkler.site">Stefan Winkler</a>
          <br>
    	  <em>IJCNN One-Minute Gradual (OMG) Emotion Behavior Challenge</em>, 2018<br>
          <a href="https://www2.informatik.uni-hamburg.de/wtm/omgchallenges/omg_emotion2018_results2018.html">leaderboard</a> |
      	  <a href="https://arxiv.org/abs/1805.00638">arxiv</a> |
          <a href="https://github.com/pengsongyou/OMG-ADSC">code</a>
          <p></p>
          <p></p>

           <strong>1st</strong> for vision-only arousal/valence prediction and <strong>2nd</strong> for overall valence prediction. </a>
        </p>
        </p>
        </td>
      </tr>
    <tr onmouseout="pepper_stop()" onmouseover="pepper_start()">
      <td width="25%">
        <div class="one">
        <div class="two" id = 'pepper_gif'><img src='media/pepper_robot.gif' width="160" height="120"></div>
        <img src='media/pepper_pic.jpg' width="160" height="120">
        </div>
        <script type="text/javascript">
        function pepper_start() {
        document.getElementById('pepper_gif').style.opacity = "1";
        }
        function pepper_stop() {
        document.getElementById('pepper_gif').style.opacity = "0";
        }
        pepper_stop()
        </script>
        </script>
      </td>
        <!--<td width="25%"><img src="media/gwas.png" alt="GWAS image from https://upload.wikimedia.org/wikipedia/commons/5/59/GWAS_loci_influencing_human_facial_and_scalp_hair_phenotypes_-_cropped.png" width="160" height="160"></td>-->
      <!--<tr>
        <td width="25%"><img src="media/benedict_1.png" alt="benedict-otter-look-a-like" width="160" height="160"></td>-->
        <td width="75%" valign="top">
        <p>
          <a href="https://github.com/PaolaArdon/Salt-Pepper">
          <papertitle>A Hybrid SLAM and Object Recognition System for Pepper Robot</papertitle>
          </a>
          <br>
          <strong>Songyou Peng*</strong>, <a href="https://kz.linkedin.com/in/kushibar">Kaisar Kushibar*</a>, <a href="https://www.edinburgh-robotics.org/students/paola-ardon-ramirez">Paola Ardon*</a>
          <br>
    	  <em>VIBOT Robotics Project</em>, 2016<br>
    	  <a href="https://arxiv.org/abs/1903.00675">arxiv</a> |
          <a href="https://www.youtube.com/watch?v=evFsnWH_bpY">video</a> |
          <a href="https://github.com/pengsongyou/msc-thesis">code</a>
          <p></p>
          <p></p>
          Apply visual SLAM on the Pepper robot along with object recognition.</a>
        </p>
        </p>
        </td>
      </tr>
      </table>
      
      <!-- Teaching -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <heading>Teaching</heading>
          <tr>
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="media/eth_logo.png" width="180">
            </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
              Teaching Assistant (Lead), <a href="https://www.cvg.ethz.ch/teaching/3dvision/"><strong>3D Vision</strong></a>, Spring 2022
              <br>
              Teaching Assistant, <a href="https://www.cvg.ethz.ch/teaching/dlseminar/"><strong>Deep Learning for Computer Vision: Seminal Work</strong></a>, Spring 2022
              <br>
              Teaching Assistant, <a href="https://www.cvg.ethz.ch/teaching/3dvision/2020/index.php"><strong>3D Vision</strong></a>, Spring 2020
              <br>
              Teaching Assistant, <a href="https://www.cvg.ethz.ch/teaching/dlseminar/2020/"><strong>Deep Learning for Computer Vision: Seminal Work</strong></a>, Spring 2020
              <br>
            </td>
          </tr>
        </table>
        <br>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="media/tue_logo.png" width="180">
            </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
              Teaching Assistant, <a href="https://uni-tuebingen.de/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/autonomous-vision/lectures/deep-learning/"><strong>Deep Learning</strong></a>, Winter 2020/2021
              <br>
            </td>
          </tr>
        </table>
      <br>
      <br>
      <br>

      <!-- Academic Services -->
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <heading>Academic Services</heading>
          <tr>
            <td>
              
              <ul>
                  <li> <strong>Conference Reviewer</strong>: CVPR, ICLR, SIGGRAPH <br>
                  <li> <strong>Journal Reviewer</strong>: TPAMI, CVIU
              </ul>
            </td>
          </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <br>
        <p align="right">
          <font size="2">
          template adapted from <a href="https://jonbarron.info/"><font size="2">this awesome website</font></a>
          <br>
          Last updated: Mar 2022
        </font>
        </p>
        </td>
      </tr>
      </table>
      <script type="text/javascript">
      var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));

      </script> <script type="text/javascript">
      try {
          var pageTracker = _gat._getTracker("UA-116734954-1");
          pageTracker._trackPageview();
          } catch(err) {}
      </script>
      <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-116734954-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-116734954-1');
</script>
    </td>
    </tr>
  </table>
  </body>
</html>
<!--  -->
