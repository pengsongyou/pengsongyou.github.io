<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 120px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 100px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="media/preview.jpg">
  <title>Songyou Peng - Homepage</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <!--<tr onmouseout="headshot_stop()" onmouseover="headshot_start()">-->
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>Songyou Peng (彭崧猷)</name>
          <!--<br>
          ruthfong at robots dot ox dot ac dot uk-->
        </p>
        <p>
          I am currently a research engineer in <a href="https://adsc.illinois.edu">Advanced Digital Sciences Center (ADSC)</a>, the Singapore-based research center of <a href="http://illinois.edu/">University of Illinois Urbana-Champaign(UIUC)</a>. 
        </p>
        <p>
          I completed a Erasmus Mundus Masters in Computer Vision and Robotics (<a href="https://www.vibot.org/">VIBOT</a>). I was fortunate to be supervised by <a href="https://vision.in.tum.de/members/cremers">Daniel Cremers</a> at <a href="https://vision.in.tum.de">Technical University of Munich (TUM)</a> and work with <a href="https://team.inria.fr/steep/en/people/peter-sturm/">Peter Sturm</a> at <a href="https://www.inria.fr/en/">INRIA Grenoble</a>. Before this, I obtained a Bachelors in Automation at <a href="http://en.xjtu.edu.cn/">Xi'an Jiaotong University (XJTU)</a>.
        </p>
<!--         <p> -->
<!--           I received a Bachelors in Computer Science at <a href="https://www.harvard.edu/">Harvard University</a> and worked with Professors <a href="http://coxlab.org/">David Cox</a> and <a href="https://www.wjscheirer.com/">Walter Scheirer</a> while there. I also spent lovely summer months at <a href="https://www.microsoft.com/">Microsoft</a>, <a href="https://www.apple.com/">Apple</a>, and <a href="https://www.deshaw.com/">D.E. Shaw</a>. -->
<!--         </p> -->
        <!--<p>I'm also supported by <a href="https://brianzhang01.github.io/">this fellow</a>.
        </p>-->
        <p align=center>
          <a href="mailto:removethisifyouarehuman-songyou.peng@adsc-create.edu.sg">Email</a> &nbsp/&nbsp
          <a href="files/resumeSongyou.pdf">CV</a> &nbsp/&nbsp
          <!--<a href="files/ruth_fong_bio.txt">Biography</a> &nbsp/&nbsp-->
<!--           <a href="https://scholar.google.com/citations?user=39cUD3gAAAAJ">Google Scholar</a> &nbsp/&nbsp -->
          <a href="https://github.com/pengsongyou">GitHub</a> &nbsp/&nbsp
          <a href="https://www.linkedin.com/in/songyou-peng-53717648/"> LinkedIn </a>
        </p>
        </td>
        <td width="33%">
          <img src="media/profile.jpg" width="250" alt="headshot">
          <!--<div class="one">
          <div class="two" id="headshot_image"><img src="media/color_headshot.png" width="250" alt="headshot"></div>
          <img src="media/bw_headshot.png" width="250" alt="headshot">
          </div>
          <script type="text/javascript">
          function headshot_start() {
          document.getElementById('headshot_image').style.opacity = "1";
          }
          function headshot_stop() {
          document.getElementById('headshot_image').style.opacity = "0";
          }
          filters_stop()
          </script>-->
        </td>
        <!--<td width="33%">
        <img src="media/bw_headshot.png" width="250">
        <img src="media/color_headshot.png" width="250">
        </td>-->
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
          <heading>News</heading>
            <ul>
              <li><b>05/2018</b>: In <a href="https://www2.informatik.uni-hamburg.de/wtm/OMG-EmotionChallenge/">OMG-Emotion Challenge 2018</a>, our ADSC team's submissions ranked <strong><font color="red">1st</font></strong> for vision-only arousal/valence prediction and <strong><font color="red">2nd</font></strong> for overall valence prediction! 
              <li><b>01/2018</b>: I joined ADSC-UIUC as a research engineer.
              <li><b>10/2017</b>: I presented my work on ICCV 2017 <a href="https://cpcv.data61.csiro.au/">Color and Photometry in Computer Vision Workshop</a>.</li>
              <li><b>06/2017</b>: I defensed my <a href="https://github.com/pengsongyou/msc-thesis">Master thesis</a>! 
            </ul>
        </td>
      </tr>
      <tr>
        <td width="100%" valign="middle">
          <heading>Research</heading>
          <p>
          I am interested in computer vision, 3D vision and deep learning.
          </p>
        </td>
      </tr>
      </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="filters_stop()" onmouseover="filters_start()">
      <td width="25%">
        <div class="one">
        <div class="two" id = 'filter_image'><img src='media/iccvw17_pic2.jpg' width="160" height="110"></div>
        <div class="two" id = 'filter_image2'><img src='media/iccvw17_pic1.jpg' width="160" height="110"></div>
        </div>
        <script type="text/javascript">
        function filters_start() {
        document.getElementById('filter_image').style.opacity = "1";
        document.getElementById('filter_image2').style.opacity = "0";
        }
        function filters_stop() {
        document.getElementById('filter_image').style.opacity = "0";
        document.getElementById('filter_image2').style.opacity = "1";
        }
        filters_stop()
        </script>
        </script>
      </td>
      <td valign="top" width="75%">
            <a href="http://openaccess.thecvf.com/content_ICCV_2017_workshops/w43/html/Peng_Depth_Super-Resolution_Meets_ICCV_2017_paper.html"><papertitle>Depth Super-Resolution Meets Uncalibrated Photometric Stereo</papertitle>
            </a>
      <br>
          <strong>Songyou Peng</strong>, <a href="https://vision.in.tum.de/members/haefner">Bjoern Haefner</a>, <a href="https://vision.in.tum.de/members/queau">Yvain Queau</a>, <a href="https://vision.in.tum.de/members/cremers">Daniel Cremers</a>
      <br>
        <em>International Conference on Computer Vision (ICCV) Workshop</em>, 2017
        <br>
        <a href="http://openaccess.thecvf.com/content_ICCV_2017_workshops/w43/html/Peng_Depth_Super-Resolution_Meets_ICCV_2017_paper.html">paper</a> /
        <a href="bib/peng2017iccvw.bib">bibtex</a> /
        <a href="files/iccvw17_presentation.pdf">slides</a> /
        <a href="https://github.com/pengsongyou/SRmeetsPS">code & data</a>
        <p></p>
        <p>A novel depth super-resolution approach for RGB-D sensors is presented.</p>
      </td>
    </tr>


    <!-- <tr onmouseout="flute_stop()" onmouseover="flute_start()" bgcolor="#ffffd0">
      <td width="25%">
        <div class="one">
        <div class="two" id = 'flute_image_2'><img src='media/flute_2.png' alt="flute" height="150" width="160"></div>
        <div class="two" id = 'flute_image_1'><img src='media/flute_1.png' alt="flute" height="150" width="160"></div> -->
        <!--<img src='media/flute_1.png' alt="flute" height="150" width="160">-->
        <!-- </div> -->
        <!-- <script type="text/javascript"> -->
        <!-- function flute_start() { -->
        <!-- document.getElementById('flute_image_2').style.opacity = "1"; -->
        <!-- document.getElementById('flute_image_1').style.opacity = "0"; -->
        <!-- } -->
        <!-- function flute_stop() { -->
        <!-- document.getElementById('flute_image_2').style.opacity = "0"; -->
        <!-- document.getElementById('flute_image_1').style.opacity = "1"; -->
        <!-- } -->
        <!-- flute_stop() -->
        <!-- </script> -->
      <!-- </td> -->
      <!-- <td valign="top" width="75%"> -->
        <!-- <a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Fong_Interpretable_Explanations_of_ICCV_2017_paper.pdf"> -->
        <!-- <papertitle>Interpretable Explanations of Black Box Algorithms by Meaningful Perturbation</papertitle> -->
        <!-- </a> -->
        <!-- <br> -->
          <!-- <strong>Ruth Fong</strong> and <a href="http://www.robots.ox.ac.uk/~vedaldi/">Andrea Vedaldi</a> -->
        <!-- <br> -->
        <!-- <em>ICCV</em>, 2017 <br> -->
        <!-- <a href="https://arxiv.org/abs/1704.03296">arxiv</a> /  -->
        <!-- <a href="http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Fong_Interpretable_Explanations_of_ICCV_2017_supplemental.pdf">supp</a> / -->
        <!-- <a href="bib/FongVedaldiICCV2017.bib">bibtex</a> /  -->
        <!-- <a href="https://github.com/ruthcfong/perturb_explanations">code</a> -->
        <!-- <p></p> -->
        <!-- <p>We developed a theoretical framework for learning "explanations" of black box functions like CNNs as well as saliency methods for identifying "where" a computer vision algorithm is looking.</p> -->
      <!-- </td>  -->
    <!-- </tr> -->
      
    <!-- <tr onmouseout="classifier_stop()" onmouseover="classifier_start()" bgcolor="#ffffd0">
      <td width="25%">
        <div class="one">
        <div class="two" id = 'classifier_image'><img src='media/classifier_2.png' width="160" height="130"></div>
        <img src='media/classifier_1.png' width="160" height="130">
        </div>
        <script type="text/javascript">
        function classifier_start() {
        document.getElementById('classifier_image').style.opacity = "1";
        }
        function classifier_stop() {
        document.getElementById('classifier_image').style.opacity = "0";
        }
        classifier_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <p><a href="https://arxiv.org/abs/1703.05463">
        <papertitle>Using Human Brain Activity to Guide Machine Learning</papertitle></a>
        <br>
          <strong>Ruth Fong</strong>, <a href="https://www.wjscheirer.com/">Walter Scheirer</a>, <a href="http://coxlab.org/">David Cox</a>
        <br>
        <em>Scientific Reports</em>, 2017 (in press)<br>
        <a href="https://arxiv.org/abs/1703.05463">arxiv</a> / 
        <a href="https://arxiv.org/src/1703.05463v2/anc/fong-et-al-supplementary.pdf">supp</a> / 
        <a href="https://dash.harvard.edu/handle/1/14398538">Harvard thesis</a> / 
        <a href="bib/FongScheirerCox2017.bib">bibtex</a> / 
        code (coming soon)
        <p></p>
        <p>We introduce a biologically-informed machine learning paradigm for object classification that biases models to better match the learned, internal representations of the visual cortex.</p>
      </td>
    </tr> -->

    <tr onmouseout="selectivity_stop()" onmouseover="selectivity_start()">
      <td width="25%">
        <div class="one">
        <div class="two" id = 'selectivity_image_2'><img src='media/ratio_shoe_shape.jpg' width="160" height="120"></div>
        <div class="two" id = 'selectivity_image_1'><img src='media/ratio_shoe_rgb.jpg' width="160" height="120"></div>
        <!--<img src='media/selectivity_1.png' width="160" height="130">-->
        </div>
        <script type="text/javascript">
        function selectivity_start() {
        document.getElementById('selectivity_image_2').style.opacity = "1";
        document.getElementById('selectivity_image_1').style.opacity = "0";
        }
        function selectivity_stop() {
        document.getElementById('selectivity_image_2').style.opacity = "0";
        document.getElementById('selectivity_image_1').style.opacity = "1";
        }
        selectivity_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <p><a href="https://github.com/pengsongyou/msc-thesis">
        <papertitle>High Quality Shape from a RGB-D Camera using Photometric Stereo</papertitle></a>
        <br>
          <strong>Songyou Peng</strong> 
        <br>
        <em>M.Sc. Dissertation</em> (advised by <a href="https://vision.in.tum.de/members/queau">Yvain Queau</a> and <a href="https://vision.in.tum.de/members/cremers">Daniel Cremers</a>)<br>
        <a href="https://github.com/pengsongyou/msc-thesis">thesis</a> /
        <a href="bib/peng2017msc.bib">bibtex</a> /
        <a href="files/msc_poster.pdf">poster</a>
        <p></p>
        <p></p>
        <p>Two novel methods which can refine the rough depth images based on the theory of photometric stereo are presented, one applies red, green and blue LED lights and the other uses only white lights.</p>
      </td>
    </tr>

      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <heading>Selected Projects</heading>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellpadding="20">
    <tr onmouseout="dna_stop()" onmouseover="dna_start()">
      <td width="25%">
        <div class="one">
        <div align="center" class="two" id='dna_gif'><img src='media/OMG_logo.png' width="150" height="80"></div>
        <div align="center" class="two" id='dna_image'><img src='media/OMG_logo.png' width="150" height="80"></div>
        </div>
        <script type="text/javascript">
        function dna_start() {
        document.getElementById('dna_gif').style.opacity = "1";
        document.getElementById('dna_image').style.opacity = "0";
        }
        function dna_stop() {
        document.getElementById('dna_gif').style.opacity = "0";
        document.getElementById('dna_image').style.opacity = "1";
        }
        dna_stop()
        </script>
      </td>
        <!--<td width="25%"><img src="media/gwas.png" alt="GWAS image from https://upload.wikimedia.org/wikipedia/commons/5/59/GWAS_loci_influencing_human_facial_and_scalp_hair_phenotypes_-_cropped.png" width="160" height="160"></td>-->
      <!--<tr>
        <td width="25%"><img src="media/benedict_1.png" alt="benedict-otter-look-a-like" width="160" height="160"></td>-->
        <td width="75%" valign="top">
        <p>
          <a href="https://github.com/PaolaArdon/Salt-Pepper">
          <papertitle>A Deep Network for Arousal-Valence Emotion Prediction with Acoustic-Visual Cues</papertitle>
          </a>
          <br>
          <strong>Songyou Peng</strong>, <a href="https://sites.google.com/site/zhangleuestc/home">Le Zhang</a>, <a href="https://team.inria.fr/perception/team-members/yutong-ban/">Yutong Ban</a>, <a href="http://people.eng.unimelb.edu.au/mengf1/">Meng Fang</a>, <a href="stefan.winkler.site">Stefan Winkler</a>
          <br>
    	  <em>IJCNN One-Minute Gradual (OMG) Emotion Behavior Challenge</em>, 2018<br>
          <a href="https://www2.informatik.uni-hamburg.de/wtm/OMG-EmotionChallenge/">leaderboard</a> /
      	  <a href="https://arxiv.org/abs/1805.00638">arxiv</a> /
          <a href="https://github.com/pengsongyou/OMG-ADSC">code</a>
          <p></p>
          <p></p>

          Our ADSC team's submissions ranked <strong>1st</strong> for vision-only arousal/valence prediction and <strong>2nd</strong> for overall valence prediction. </a>
        </p>
        </p>
        </td>
      </tr>
    <tr onmouseout="dna_stop()" onmouseover="dna_start()">
      <td width="25%">
        <div class="one">
        <div align="center" class="two" id='dna_gif'><img src='media/pepper_pic.jpg' width="150" height="120"></div>
        <div align="center" class="two" id='dna_image'><img src='media/pepper_pic.jpg' width="150" height="120"></div>
        </div>
        <script type="text/javascript">
        function dna_start() {
        document.getElementById('dna_gif').style.opacity = "1";
        document.getElementById('dna_image').style.opacity = "0";
        }
        function dna_stop() {
        document.getElementById('dna_gif').style.opacity = "0";
        document.getElementById('dna_image').style.opacity = "1";
        }
        dna_stop()
        </script>
      </td>
        <!--<td width="25%"><img src="media/gwas.png" alt="GWAS image from https://upload.wikimedia.org/wikipedia/commons/5/59/GWAS_loci_influencing_human_facial_and_scalp_hair_phenotypes_-_cropped.png" width="160" height="160"></td>-->
      <!--<tr>
        <td width="25%"><img src="media/benedict_1.png" alt="benedict-otter-look-a-like" width="160" height="160"></td>-->
        <td width="75%" valign="top">
        <p>
          <a href="https://github.com/PaolaArdon/Salt-Pepper">
          <papertitle>A Hybrid SLAM and Object Recognition System for Pepper Robot</papertitle>
          </a>
          <br>
          <strong>Songyou Peng</strong>, <a href="https://kz.linkedin.com/in/kushibar">Kaisar Kushibar</a>, <a href="https://www.edinburgh-robotics.org/students/paola-ardon-ramirez">Paola Ardon</a>
          <br>
    	  <em>VIBOT Robotics Project</em>, 2016<br>
          <a href="https://www.youtube.com/watch?v=evFsnWH_bpY">video</a> /
          <a href="https://github.com/pengsongyou/msc-thesis">code</a>
          <p></p>
          <p></p>
          We apply visual SLAM on the Pepper robot along with object recognition.</a>
        </p>
        </p>
        </td>
      </tr>
      </table>
      
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <br>
        <p align="right">
          <font size="2">
          <a href="https://jonbarron.info/"><font size="2">I owe this guy a cup of beer</font></a>
          <br>
          Last updated: May 2018
        </font>
        </p>
        </td>
      </tr>
      </table>
      <script type="text/javascript">
      var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));

      </script> <script type="text/javascript">
      try {
          var pageTracker = _gat._getTracker("UA-116734954-1");
          pageTracker._trackPageview();
          } catch(err) {}
      </script>
      <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-116734954-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-116734954-1');
</script>
    </td>
    </tr>
  </table>
  </body>
</html>
